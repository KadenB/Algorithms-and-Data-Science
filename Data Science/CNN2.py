from __future__ import print_function
import keras
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
import os
import pickle
os.environ['KMP_DUPLICATE_LIB_OK']='True'

# followed a similar structure to the tutorial here but added extra layers and changed parameters : https://keras.io/examples/cifar10_cnn/
# mainly because i wanted to compare the accuracy of the base model to that of the changed cifar data
batch_size = 100
num_classes = 10
epochs_1 = 100
data_augmentation = False

save_dir = os.path.join(os.getcwd(), 'saved_models')
model_name = 'Cifar10ModelNoAug.h5' # change model name for changes

# The data, split between train and test sets:
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
# Load our created data from the boundingbox script
x_train_cust = pickle.load(open( "Cifar_boxed_train.p", "rb" ))
x_test_cust = pickle.load(open( "Cifar_boxed_test.p", "rb" ))
print('x_train_cust shape:', x_train_cust.shape)
print(x_train_cust.shape[0], 'train samples')
print(x_test_cust.shape[0], 'test samples')

# 
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=x_train_cust.shape[1:]))
model.add(Activation('elu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('elu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.2))

model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('elu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('elu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.2))

model.add(Conv2D(128, (3, 3), padding='same'))
model.add(Activation('elu'))
model.add(Conv2D(128, (3, 3)))
model.add(Activation('elu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.2))

model.add(Flatten())
model.add(Activation('elu'))
model.add(Dropout(0.3))
model.add(Dense(num_classes))
model.add(Activation('softmax'))


opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)
adam_opt =keras.optimizers.adam(lr = .0001, decay = 1e-4)

model.compile(loss='categorical_crossentropy',
              optimizer=adam_opt,
              metrics=['accuracy'])

x_train_cust = x_train_cust.astype('float32')
x_test_cust = x_test_cust.astype('float32')
x_train_cust /= 255
x_test_cust /= 255

if not data_augmentation:
    print('No augmentation')
    model.fit(x_train_cust, y_train,
              batch_size=batch_size,
              epochs=epochs_1,
              validation_data=(x_test_cust, y_test),
              shuffle=True)
else:
    print('Using Augmentation')
    # the augmented model performed worse than the non augmented model
    datagen = ImageDataGenerator(
        featurewise_center=True,  
        rotation_range=30, 
        fill_mode='nearest',
        horizontal_flip=True, 
        vertical_flip=True)

    datagen.fit(x_train_cust)

    #Fit the model on the batches generated by datagen.flow().
    model.fit_generator(datagen.flow(x_train_cust, y_train,
                                     batch_size=batch_size),
                       steps_per_epoch= x_train_cust.shape[0]/batch_size ,epochs=epochs_1,
                        validation_data=(x_test_cust, y_test), workers=4 )
 
# Save model and weights
if not os.path.isdir(save_dir):
    os.makedirs(save_dir)
model_path = os.path.join(save_dir, model_name)
model.save(model_path)
print('Saved trained model at %s ' % model_path)

# Score trained model.
scores = model.evaluate(x_test_cust, y_test, verbose=1)
print('Test loss:', scores[0])
print('Test accuracy:', scores[1])


# scores for the  non augmented model were about 76% after 100 epochs
# scores for the augmented model were about 50%


# other ideas, implement early stopping or learning weight adjustments depending on score developement per epoch